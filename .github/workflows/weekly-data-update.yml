name: Weekly Data Collection

on:
  schedule:
    # Run every Monday at 9:00 AM UTC (4:00 AM EST)
    - cron: '0 9 * * 1'
  workflow_dispatch: # Allow manual trigger

env:
  YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
  FRED_API_KEY: ${{ secrets.FRED_API_KEY }}

jobs:
  collect-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          pip install -r data-collection/requirements.txt

      - name: Run YouTube collectors
        working-directory: data-collection
        run: |
          echo "Running YouTube collectors..."
          python healthcare-youtube-collector.py || true
          python ai-psychosis-youtube-collector.py || true
          python subscription-overload-youtube-collector.py || true
          python wage-stagnation-youtube-collector.py || true
          python housing-despair-youtube-collector.py || true
          python dating-app-despair-youtube-collector.py || true
          python layoff-watch-youtube-collector.py || true
          python airline-chaos-youtube-collector.py || true

      # Reddit collectors removed from CI - Reddit blocks GitHub Actions IPs (403).
      # Run Reddit collection locally: python run_weekly_update.py --reddit-only

      - name: Run TikTok collector
        working-directory: data-collection
        run: |
          echo "Running TikTok collector (via YouTube compilations)..."
          python tiktok-youtube-collector.py || true

      - name: Run FRED official scores collector
        working-directory: data-collection
        run: |
          echo "Running FRED API collector for official scores..."
          python fred-collector.py || true

      - name: Run Hacker News collector
        working-directory: data-collection
        run: |
          echo "Running Hacker News collector (no auth needed)..."
          python hackernews-collector.py || true

      - name: Run CFPB complaint collector
        working-directory: data-collection
        run: |
          echo "Running CFPB complaint collector (no auth needed)..."
          python cfpb-collector.py || true

      - name: Run Bluesky collector
        working-directory: data-collection
        run: |
          echo "Running Bluesky collector (no auth needed)..."
          python bluesky-collector.py || true

      - name: Check if new data was collected
        id: check_data
        working-directory: data-collection
        run: |
          # Count data files modified in the last 10 minutes (from this run)
          NEW_FILES=$(find collected-data/ \( -name "*.csv" -o -name "*.json" \) -newer /proc/1/cmdline -not -empty 2>/dev/null | wc -l)
          # Also check file sizes - files under 200 bytes are likely header-only
          GOOD_FILES=$(find collected-data/ \( -name "*.csv" -o -name "*.json" \) -newer /proc/1/cmdline -size +200c 2>/dev/null | wc -l)
          echo "New data files: $NEW_FILES (with data: $GOOD_FILES)"

          if [ "$GOOD_FILES" -eq "0" ]; then
            echo "WARNING: No new data collected in this run."
            echo "All collectors may have failed (check API key, quotas, network)."
            echo "has_new_data=false" >> $GITHUB_OUTPUT
          else
            echo "has_new_data=true" >> $GITHUB_OUTPUT
          fi

      - name: Deduplicate Reddit posts
        if: steps.check_data.outputs.has_new_data == 'true'
        working-directory: data-collection
        run: |
          echo "Deduplicating Reddit posts across metrics..."
          python deduplicate_reddit_posts.py

      - name: Calculate new scores
        if: steps.check_data.outputs.has_new_data == 'true'
        working-directory: data-collection
        run: |
          echo "Calculating social scores..."
          python calculate_all_social_scores.py

      - name: Update metricDetailData.ts
        if: steps.check_data.outputs.has_new_data == 'true'
        working-directory: data-collection
        run: |
          echo "Updating TypeScript data file..."
          python update_metric_data.py

      - name: Update sample data
        if: steps.check_data.outputs.has_new_data == 'true'
        working-directory: data-collection
        run: |
          echo "Updating sample data from collected entries..."
          python update_sample_data.py

      - name: List collected data
        run: |
          echo "Collected data files:"
          ls -la data-collection/collected-data/

      - name: Set up Node.js
        if: steps.check_data.outputs.has_new_data == 'true'
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies and build
        if: steps.check_data.outputs.has_new_data == 'true'
        run: |
          npm ci
          npm run build

      - name: Configure Git
        if: steps.check_data.outputs.has_new_data == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

      - name: Commit and push changes
        if: steps.check_data.outputs.has_new_data == 'true'
        run: |
          git add data-collection/collected-data/
          git add lib/metricDetailData.ts
          git diff --staged --quiet || git commit -m "Weekly data update - $(date +'%Y-%m-%d')

          Automated collection from YouTube, TikTok, Hacker News, CFPB, Bluesky, and FRED.
          Updated scores and level distributions in metricDetailData.ts."
          git push

  notify-on-failure:
    needs: collect-data
    if: failure()
    runs-on: ubuntu-latest
    steps:
      - name: Notify failure
        run: |
          echo "Data collection failed. Check workflow logs for details."
